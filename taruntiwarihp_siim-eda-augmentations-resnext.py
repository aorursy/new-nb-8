from IPython.display import YouTubeVideo,HTML

YouTubeVideo("mkYBxfKDyv0", width=800, height=500)
import glob, pylab, pandas as pd

import pydicom, numpy as np

from os import listdir

from os.path import isfile, join

import matplotlib.pylab as plt

import matplotlib.pyplot as plt2

from plotly.offline import init_notebook_mode

import plotly.graph_objs as go

from plotly import tools

import os

import seaborn as sns

from keras import layers

from sklearn.model_selection import train_test_split

from tensorflow.keras.layers import *

from keras.applications import DenseNet121

from keras.preprocessing.image import ImageDataGenerator

from keras.callbacks import Callback, ModelCheckpoint

from keras.preprocessing.image import ImageDataGenerator

from keras.models import Sequential

from keras.optimizers import Adam

import tensorflow as tf

from plotly.tools import FigureFactory as FF

import plotly

from tqdm import tqdm

import cv2

from PIL import Image

from plotly.offline import iplot

import cufflinks

import cv2 as cv

from mpl_toolkits.mplot3d.art3d import Poly3DCollection


plotly.io.templates.default = "none"

import altair as alt; import altair_render_script

plt.style.use("fivethirtyeight")

def _generate_bar_plot_hor(df, col, title, color, w=None, h=None, lm=0, limit=100):

    cnt_srs = df[col].value_counts()[:limit]

    trace = go.Bar(y=cnt_srs.index[::-1], x=cnt_srs.values[::-1], orientation = 'h',

        marker=dict(color=color))



    layout = dict(title=title, margin=dict(l=lm), width=w, height=h)

    data = [trace]

    annotations = []

    annotations += [go.layout.Annotation(x=673, y=100, xref="x", yref="y", text="(Most Popular)", showarrow=False, arrowhead=7, ax=0, ay=-40)]

    fig = go.Figure(data=data, layout=layout)

    iplot(fig)

    

cufflinks.go_offline()

cufflinks.set_config_file(world_readable=True, theme='pearl')
# Images Example

train_images_dir = '../input/siim-isic-melanoma-classification/train/'

train_images = [f for f in listdir(train_images_dir) if isfile(join(train_images_dir, f))]

test_images_dir = '../input/siim-isic-melanoma-classification/test/'

test_images = [f for f in listdir(test_images_dir) if isfile(join(test_images_dir, f))]

print('5 Training images', train_images[:5]) # Print the first 5
train = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')

test = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')
train.head()
fig=plt.figure(figsize=(15, 10))

columns = 5; rows = 4

for i in range(1, columns*rows +1):

    ds = pydicom.dcmread(train_images_dir + train_images[i])

    fig.add_subplot(rows, columns, i)

    plt.imshow(-ds.pixel_array, cmap=plt.cm.bone)

    fig.add_subplot
train.head()
# Function to calculate missing values by column# Funct 

def missing_values_table(df):

        # Total missing values

        mis_val = df.isnull().sum()

        

        # Percentage of missing values

        mis_val_percent = 100 * df.isnull().sum() / len(df)

        

        # Make a table with the results

        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)

        

        # Rename the columns

        mis_val_table_ren_columns = mis_val_table.rename(

        columns = {0 : 'Missing Values', 1 : '% of Total Values'})

        

        # Sort the table by percentage of missing descending

        mis_val_table_ren_columns = mis_val_table_ren_columns[

            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(

        '% of Total Values', ascending=False).round(1)

        

        # Print some summary information

        print ("Your selected dataframe has " + str(df.shape[1]) + " columns.\n"      

            "There are " + str(mis_val_table_ren_columns.shape[0]) +

              " columns that have missing values.")

        

        # Return the dataframe with missing information

        return mis_val_table_ren_columns
# Missing values statistics

missing_values = missing_values_table(train)

missing_values.head(20)
missing_values = missing_values_table(test)

missing_values.head(20)
train['age_approx2'] = train['age_approx'].fillna(0).astype('str')
holiday_json = {

"name": "flare",

"children": [

{

"name": "Affected Part",

"children":[

{

    "name": "Torso",

         "children": [

              {"name": "Chest", "size": 3.0},

              {"name": "Stomach (outer covering)", "size": 1.0},

              {"name": "Back of torso", "size": 2.0}

     ]

},

{

    "name": "Head/Neck",

         "children": [

              {"name": "Eyes", "size": 3.0},

              {"name": "Nose", "size": 1.0},

              {"name": "Neck", "size": 2.0},

              {"name": "Lips", "size": 1.0},

              {"name": "Ears", "size": 1.0}

     ]

},

{"name": "Upper extremity                                      ", "size": 3.0},

{"name": "Lower extremity                                      ", "size": 3.0},

{"name": "Palms/soles                                          ", "size": 2.0},

{"name": "Oral/genitalia                                       ", "size": 1.0}

]

},

{

"name":  "diagnosis",

"children":[

{"name": "unkown",       "size": 10.0},

{"name": "nevus",       "size": 4.0},

{"name": "melanoma",   "size": 3.0},

{"name": "seborheic keratosis",       "size": 2.0},

{"name": "lichenoid keratosis",         "size": 2.0},

{"name": "solar lentigo",                          "size": 1.0},

{"name": "atypical melanocytic proliferation",     "size": 1.0},

{"name": "cafe-au-lait macule", "size": 1.0}

]

},

{

"name": "Target feature",

"children": [

{"name": "malignant          ", "size": 1.0},

{"name": "benign                    ", "size": 6.0}

]

},

{

"name": "Age (approximated)",

"children":[

{

    "name": "0",

         "children": [

              {"name": "1", "size": 1.0},

              {"name": "2", "size": 1.0},

              {"name": "3", "size": 1.0},

              {"name": "4", "size": 1.0},

              {"name": "5", "size": 1.0}

     ]

},

{

    "name": "5",

         "children": [

              {"name": "6", "size": 1.0},

              {"name": "7", "size": 1.0},

              {"name": "8", "size": 1.0},

              {"name": "9", "size": 1.0},

              {"name": "10", "size": 1.0}

     ]

},

{

    "name": "20",

         "children": [

              {"name": "11", "size": 1.0},

              {"name": "12", "size": 1.0},

              {"name": "13", "size": 1.0},

              {"name": "14", "size": 1.0},

              {"name": "15", "size": 1.0},

              {"name": "16", "size": 1.0},

              {"name": "17", "size": 1.0},

              {"name": "18", "size": 2.0},

              {"name": "19", "size": 1.0},

              {"name": "20", "size": 1.0}

     ]

},

{

    "name": "25",

         "children": [

              {"name": "21", "size": 1.0},

              {"name": "22", "size": 1.0},

              {"name": "23", "size": 2.0},

              {"name": "24", "size": 1.0},

              {"name": "25", "size": 3.0}

     ]

},

{

    "name": "30",

         "children": [

              {"name": "26", "size": 2.0},

              {"name": "27", "size": 1.0},

              {"name": "28", "size": 2.0},

              {"name": "29", "size": 2.0},

              {"name": "30", "size": 1.0}

     ]

},

{

    "name": "40",

         "children": [

              {"name": "31", "size": 1.0},

              {"name": "32", "size": 3.0},

              {"name": "33", "size": 2.0},

              {"name": "34", "size": 1.0},

              {"name": "35", "size": 3.0},

              {"name": "36", "size": 2.0},

              {"name": "37", "size": 1.0},

              {"name": "38", "size": 2.0},

              {"name": "39", "size": 1.0},

              {"name": "40", "size": 4.0}

     ]

},

{

    "name": "45",

         "children": [

              {"name": "41", "size": 5.0},

              {"name": "42", "size": 4.0},

              {"name": "43", "size": 4.0},

              {"name": "44", "size": 5.0},

              {"name": "45", "size": 5.0}

     ]

},

{

    "name": "50",

         "children": [

              {"name": "46", "size": 4.0},

              {"name": "47", "size": 5.0},

              {"name": "48", "size": 4.0},

              {"name": "49", "size": 4.0},

              {"name": "50", "size": 3.0}

     ]

},

{

    "name": "55",

         "children": [

              {"name": "51", "size": 3.0},

              {"name": "52", "size": 3.0},

              {"name": "53", "size": 3.0},

              {"name": "54", "size": 2.0},

              {"name": "55", "size": 3.0}

     ]

},

{

    "name": "60",

         "children": [

              {"name": "56", "size": 3.0},

              {"name": "57", "size": 3.0},

              {"name": "58", "size": 2.0},

              {"name": "59", "size": 2.0},

              {"name": "60", "size": 4.0}

     ]

},

{

    "name": "65",

         "children": [

              {"name": "61", "size": 2.0},

              {"name": "62", "size": 3.0},

              {"name": "63", "size": 4.0},

              {"name": "64", "size": 3.0},

              {"name": "65", "size": 3.0}

     ]

},

{

    "name": "70",

         "children": [

              {"name": "66", "size": 3.0},

              {"name": "67", "size": 2.0},

              {"name": "68", "size": 2.0},

              {"name": "69", "size": 2.0},

              {"name": "70", "size": 2.0}

     ]

},

{

    "name": "75",

         "children": [

              {"name": "71", "size": 2.0},

              {"name": "72", "size": 2.0},

              {"name": "73", "size": 1.0},

              {"name": "74", "size": 1.0},

              {"name": "75", "size": 2.0}  

         ]

},

{

    "name": "80",

         "children": [

              {"name": "76", "size": 2.0},

              {"name": "77", "size": 2.0},

              {"name": "78", "size": 1.0},

              {"name": "79", "size": 1.0},

              {"name": "80", "size": 1.0}

     ]

},

{

    "name": "85",

         "children": [

              {"name": "81", "size": 2.0},

              {"name": "82", "size": 1.0},

              {"name": "83", "size": 1.0},

              {"name": "84", "size": 1.0},

              {"name": "85", "size": 1.0}

     ]

},

{

    "name": "90",

         "children": [

              {"name": "86", "size": 1.0},

              {"name": "87", "size": 1.0},

              {"name": "88", "size": 1.0},

              {"name": "89", "size": 1.0},

              {"name": "90", "size": 1.0},

     ]

},

]

}

] 

}               



import IPython

import json



with open('output.json', 'w') as outfile:  

    json.dump(holiday_json, outfile)

pd.read_json('output.json').head()



#Embedding the html string

html_string = """

<!DOCTYPE html>

<meta charset="utf-8">

<style>



.node {

  cursor: pointer;

}



.node:hover {

  stroke: #000;

  stroke-width: 1.5px;

}



.node--leaf {

  fill: white;

}



.label {

  font: 11px "Helvetica Neue", Helvetica, Arial, sans-serif;

  text-anchor: middle;

  text-shadow: 0 1px 0 #fff, 1px 0 0 #fff, -1px 0 0 #fff, 0 -1px 0 #fff;

}



.label,

.node--root,

.node--leaf {

  pointer-events: none;

}



</style>

<svg width="760" height="760"></svg>

"""



js_string="""

 require.config({

    paths: {

        d3: "https://d3js.org/d3.v4.min"

     }

 });



  require(["d3"], function(d3) {



   console.log(d3);



var svg = d3.select("svg"),

    margin = 20,

    diameter = +svg.attr("width"),

    g = svg.append("g").attr("transform", "translate(" + diameter / 2 + "," + diameter / 2 + ")");



var color = d3.scaleSequential(d3.interpolateViridis)

    .domain([-4, 4]);



var pack = d3.pack()

    .size([diameter - margin, diameter - margin])

    .padding(2);



d3.json("output.json", function(error, root) {

  if (error) throw error;



  root = d3.hierarchy(root)

      .sum(function(d) { return d.size; })

      .sort(function(a, b) { return b.value - a.value; });



  var focus = root,

      nodes = pack(root).descendants(),

      view;



  var circle = g.selectAll("circle")

    .data(nodes)

    .enter().append("circle")

      .attr("class", function(d) { return d.parent ? d.children ? "node" : "node node--leaf" : "node node--root"; })

      .style("fill", function(d) { return d.children ? color(d.depth) : null; })

      .on("click", function(d) { if (focus !== d) zoom(d), d3.event.stopPropagation(); });



  var text = g.selectAll("text")

    .data(nodes)

    .enter().append("text")

      .attr("class", "label")

      .style("fill-opacity", function(d) { return d.parent === root ? 1 : 0; })

      .style("display", function(d) { return d.parent === root ? "inline" : "none"; })

      .text(function(d) { return d.data.name; });



  var node = g.selectAll("circle,text");



  svg

      .style("background", color(-1))

      .on("click", function() { zoom(root); });



  zoomTo([root.x, root.y, root.r * 2 + margin]);



  function zoom(d) {

    var focus0 = focus; focus = d;



    var transition = d3.transition()

        .duration(d3.event.altKey ? 7500 : 750)

        .tween("zoom", function(d) {

          var i = d3.interpolateZoom(view, [focus.x, focus.y, focus.r * 2 + margin]);

          return function(t) { zoomTo(i(t)); };

        });



    transition.selectAll("text")

      .filter(function(d) { return d.parent === focus || this.style.display === "inline"; })

        .style("fill-opacity", function(d) { return d.parent === focus ? 1 : 0; })

        .on("start", function(d) { if (d.parent === focus) this.style.display = "inline"; })

        .on("end", function(d) { if (d.parent !== focus) this.style.display = "none"; });

  }



  function zoomTo(v) {

    var k = diameter / v[2]; view = v;

    node.attr("transform", function(d) { return "translate(" + (d.x - v[0]) * k + "," + (d.y - v[1]) * k + ")"; });

    circle.attr("r", function(d) { return d.r * k; });

  }

});

  });

 """

from IPython.core.display import display, HTML, Javascript

h2 = display(HTML("""<h2 style="font-family: 'Garamond';"> Zoomable Circle Packing </h2> <i>This is all primarily based on Anisotropic's work: upvote there, I admire his work a lot.</i>"""))

h = display(HTML(html_string))

j = IPython.display.Javascript(js_string)

IPython.display.display_javascript(j)



doc = {"name": "Characteristics", "color": "#ffae00", "percent": "", "value": "", "size": 25, "children": []}



def getsize(s):

    if s > 80:

        return 30

    elif s > 65:

        return 20

    elif s > 45:

        return 15

    elif s > 35:

        return 12

    elif s > 20:

        return 10 

    else:

        return 5

def vcs(col):

    vc = train[col].value_counts()

    keys = vc.index

    vals = vc.values 

    

    ddoc = {"name": col, "color": "#be5eff", "percent": "", "value": "", "size": 25, "children": []}

    for i,x in enumerate(keys):

        percent = round(100 * float(vals[i]) / sum(vals), 2)

        size = getsize(percent)

        collr = "#fc5858"

 

        doc = {"name": x+" ("+str(percent)+"%)", "color": collr, "percent": str(percent), "value": str(vals[i]), "size": size, "children": []}

        ddoc['children'].append(doc)

    return ddoc



# Coding Backgrounds

doc['children'].append(vcs('anatom_site_general_challenge'))

doc['children'].append(vcs('benign_malignant'))

doc['children'].append(vcs('diagnosis'))

doc['children'].append(vcs('sex'))



html_d1 = """<!DOCTYPE html><style>.node text {font: 12px sans-serif;}.link {fill: none;stroke: #ccc;stroke-width: 2px;}</style><svg id="four" width="760" height="900" font-family="sans-serif" font-size="10" text-anchor="middle"></svg>"""

js_d1="""

require(["d3"], function(d3) {

var treeData = """ +json.dumps(doc) + """

var root, margin = {

        top: 20,

        right: 90,

        bottom: 120,

        left: 90

    },

    width = 960 - margin.left - margin.right,

    height = 660,

    svg = d3.select("#four").attr("width", width + margin.right + margin.left).attr("height", height + margin.top + margin.bottom).append("g").attr("transform", "translate(" + margin.left + "," + margin.top + ")"),

    i = 0,

    duration = 750,

    treemap = d3.tree().size([height, width]);



function collapse(t) {

    t.children && (t._children = t.children, t._children.forEach(collapse), t.children = null)

}



function update(n) {

    var t = treemap(root),

        r = t.descendants(),

        e = t.descendants().slice(1);

    r.forEach(function(t) {

        t.y = 180 * t.depth

    });

    var a = svg.selectAll("g.node").data(r, function(t) {

            return t.id || (t.id = ++i)

        }),

        o = a.enter().append("g").attr("class", "node").attr("transform", function(t) {

            return "translate(" + n.y0 + "," + n.x0 + ")"

        }).on("click", function(t) {

            t.children ? (t._children = t.children, t.children = null) : (t.children = t._children, t._children = null);

            update(t)

        });

    o.append("circle").attr("class", "node").attr("r", function(t) {

        return t.data.size

    }).style("fill", function(t) { return t.data.color;

    }), o.append("text").attr("dy", ".35em").attr("x", function( t) {

        return t.children || t._children ? -13 : 13

    }).attr("text-anchor", function(t) {

        return t.children || t._children ? "end" : "start"

    }).text(function(t) {

        return t.data.name

    });

    var c = o.merge(a);

    c.transition().duration(duration).attr("transform", function(t) {

        return "translate(" + t.y + "," + t.x + ")"

    }), c.select("circle.node").attr("r", function(t) {

        return t.data.size

    }).style("fill", function(t) {

        return t.data.color

    }).attr("cursor", "pointer");

    var l = a.exit().transition().duration(duration).attr("transform", function(t) {

        return "translate(" + n.y + "," + n.x + ")"

    }).remove();

    l.select("circle").attr("r", function(t) {

        return t.data.size

    }), l.select("text").style("fill-opacity", 1e-6);

    var d = svg.selectAll("path.link").data(e, function(t) {

        return t.id

    });

    console.log(), d.enter().insert("path", "g").attr("class", "link").attr("d", function(t) {

        var r = {

            x: n.x0,

            y: n.y0

        };

        return u(r, r)

    }).merge(d).transition().duration(duration).attr("d", function(t) {

        return u(t, t.parent)

    });

    d.exit().transition().duration(duration).attr("d", function(t) {

        var r = {

            x: n.x,

            y: n.y

        };

        return u(r, r)

    }).remove();



    function u(t, r) {

        var n = "M" + t.y + "," + t.x + "C" + (t.y + r.y) / 2 + "," + t.x + " " + (t.y + r.y) / 2 + "," + r.x + " " + r.y + "," + r.x;

        return console.log(n), n

    }

    r.forEach(function(t) {

        t.x0 = t.x, t.y0 = t.y

    })

}(root = d3.hierarchy(treeData, function(t) {

    return t.children

})).x0 = height / 2, root.y0 = 0, root.children.forEach(collapse), update(root);

});

"""

js7m="""require.config({

    paths: {

        d3: "https://d3js.org/d3.v4.min"

     }

 });

 

 require(["d3"], function(d3) {// Dimensions of sunburst.

 

 





var svg = d3.select("#fd"),

    width = +svg.attr("width"),

    height = +svg.attr("height");



var color = d3.scaleOrdinal(d3.schemeCategory20);



var simulation = d3.forceSimulation()



    .force("link", d3.forceLink().id(function(d) { return d.id; }).distance(120).strength(1))

    .force("charge", d3.forceManyBody().strength(-155))

    .force("center", d3.forceCenter(width / 2, height / 2));



d3.json("fd.json", function(error, graph) {

  if (error) throw error;



  var link = svg.append("g")

      .attr("class", "links")

    .selectAll("line")

    .data(graph.links)

    .enter().append("line")

      .attr("stroke-width", function(d) { return Math.sqrt(d.value); });



// Define the div for the tooltip

var div = d3.select("body").append("div")	

    .attr("class", "tooltip")				

    .style("opacity", 0);



  var node = svg.append("g")

      .attr("class", "nodes")

    .selectAll("circle")

    .data(graph.nodes)

    .enter().append("circle")

      .attr("r", function(d) {return d.size})

      .attr("fill", function(d) { return color(d.group); })

      .call(d3.drag()

          .on("start", dragstarted)

          .on("drag", dragged)

          .on("end", dragended)).on("mouseover", function(d) {		

            div.transition()		

                .duration(200)		

                .style("opacity", .9);		

            div	.html(d.id )

                .style("left", (d3.event.pageX) + "px")		

                .style("top", (d3.event.pageY - 28) + "px");	

            })					

        .on("mouseout", function(d) {		

            div.transition()		

                .duration(500)		

                .style("opacity", 0);	

        });

          

    

// node.append("title")

  //  .text(function(d) { return d.id; });



  simulation

      .nodes(graph.nodes)

      .on("tick", ticked);

      



  simulation.force("link")

      .links(graph.links);



  function ticked() {

    link

        .attr("x1", function(d) { return d.source.x; })

        .attr("y1", function(d) { return d.source.y; })

        .attr("x2", function(d) { return d.target.x; })

        .attr("y2", function(d) { return d.target.y; });



    node

        .attr("cx", function(d) { return d.x; })

        .attr("cy", function(d) { return d.y; });

  }

});



function dragstarted(d) {

  if (!d3.event.active) simulation.alphaTarget(0.3).restart();

  d.fx = d.x;

  d.fy = d.y;

}



function dragged(d) {

  d.fx = d3.event.x;

  d.fy = d3.event.y;

}



function dragended(d) {

  if (!d3.event.active) simulation.alphaTarget(0);

  d.fx = null;

  d.fy = null;

}

 });

"""



h = display(HTML(html_d1))

j = IPython.display.Javascript(js_d1)

IPython.display.display_javascript(j)

ds = pydicom.dcmread(train_images_dir + train_images[0])

from skimage import measure

def plot_3d(image, threshold=-300):

    p = image.transpose(2,1,0)

    

    verts, faces, norm, val = measure.marching_cubes_lewiner(p, threshold, step_size=1, allow_degenerate=True) 

    fig = plt.figure(figsize=(10, 10))

    ax = fig.add_subplot(111, projection='3d')



    # Fancy indexing: `verts[faces]` to generate a collection of triangles

    mesh = Poly3DCollection(verts[faces], alpha=0.70)

    face_color = [0.45, 0.45, 0.75]

    mesh.set_facecolor(face_color)

    ax.add_collection3d(mesh)



    ax.set_xlim(0, p.shape[0])

    ax.set_ylim(0, p.shape[1])

    ax.set_zlim(0, p.shape[2])

    plt.title("3-dimensional representation of an image")

    plt.show()



plot_3d(ds.pixel_array,threshold=100)
df = pd.DataFrame(train.benign_malignant.value_counts())

df['name'] = df.index

alt.Chart(df).mark_bar().encode(

    x='name',

    y='benign_malignant',

    tooltip=["name","benign_malignant"]

).interactive()
fig=plt.figure(figsize=(15, 10))

columns = 4; rows = 5

for i in range(1, columns*rows +1):

    # added the grid lines for pixel purposes

    ds = pydicom.dcmread(train_images_dir + train[train['benign_malignant']=='benign']['image_name'][i] + '.dcm')

    fig.add_subplot(rows, columns, i)

    plt.imshow(ds.pixel_array, cmap=plt.cm.bone)

    fig.add_subplot
train.benign_malignant.value_counts()
# BY SERGEI ISSAEV

vals = train[train['benign_malignant']=='malignant']['image_name'].index.values

fig=plt.figure(figsize=(15, 10))

columns = 4; rows = 5

for i in range(1, columns*rows +1):

    # added the grid lines for pixel purposes



    ds = pydicom.dcmread(train_images_dir + train[train['benign_malignant']=='malignant']['image_name'][vals[i]] + '.dcm')

    fig.add_subplot(rows, columns, i)

    plt.imshow(ds.pixel_array, cmap=plt.cm.bone)

    fig.add_subplot
df = pd.DataFrame(train.anatom_site_general_challenge.value_counts())

df['name'] = df.index

alt.Chart(df).mark_bar().encode(

    x='name',

    y='anatom_site_general_challenge',

    tooltip=["name","anatom_site_general_challenge"]

).interactive()
import squarify

fig = plt.figure(figsize=(25, 21))

marrimeko=train.anatom_site_general_challenge.value_counts().to_frame()

ax = fig.add_subplot(111, aspect="equal")

ax = squarify.plot(sizes=marrimeko['anatom_site_general_challenge'].values,label=marrimeko.index,

              color=sns.color_palette('cubehelix_r', 28), alpha=1)

ax.set_xticks([])

ax.set_yticks([])

fig=plt.gcf()

fig.set_size_inches(40,25)

plt.title("Treemap of cancer counts across different parts", fontsize=18)

plt.show();
_generate_bar_plot_hor(train, 'anatom_site_general_challenge', '<b>Affected Location</b>', '#66f992', 800, 400, 200)
def view_images(images, title = '', aug = None):

    width = 6

    height = 4

    fig, axs = plt.subplots(height, width, figsize=(15,5))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')



    plt.subplots_adjust(wspace=0, hspace=0)

    plt.suptitle(title)

    plt.show()

for i in train['anatom_site_general_challenge'].unique()[:4]:

    view_images(train[train['anatom_site_general_challenge']==i]['image_name'], title=f"Growth in the {i}")

for i in train['anatom_site_general_challenge'][:1].unique():

    view_images(train[train['anatom_site_general_challenge']==i][train['target']==1]['image_name'], title=f"Malignant in the {i}");
_generate_bar_plot_hor(train, 'diagnosis', '<b>Affected Location</b>', '#f2b5bc', 800, 400, 200)
fig = plt.figure(figsize=(25, 21))

marrimeko=train.diagnosis.value_counts().to_frame()

ax = fig.add_subplot(111, aspect="equal")

ax = squarify.plot(sizes=marrimeko['diagnosis'].values,label=marrimeko.index,

              color=sns.color_palette('cubehelix_r', 28), alpha=1)

ax.set_xticks([])

ax.set_yticks([])

fig=plt.gcf()

fig.set_size_inches(40,25)

plt.title("Treemap of cancer counts across different ages", fontsize=18)

plt.show();
view_images(train[train['diagnosis']=='nevus']['image_name'], title="Nevus pigmentatious growth");
view_images(train[train['diagnosis']=='melanoma']['image_name'], title="Melanoma's growth");
train.diagnosis.value_counts()
def view_images_sp(images, title = '', aug = None):

    width = 1

    height = 1

    fig, axs = plt.subplots(height, width, figsize=(15,5))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        plt.imshow(image, cmap=plt.cm.bone) 

        axs.axis('off')

    plt.subplots_adjust(wspace=0, hspace=0)

    plt.suptitle(title)

    plt.show()

view_images(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo's growth");
view_images(train[train['diagnosis']=='lichenoid keratosis']['image_name'], title="Lichenoid's growth");
view_images(train[train['diagnosis']=='seborrheic keratosis']['image_name'], title="Lichenoid's growth");
view_images_sp(train[train['diagnosis']=='atypical melanocytic proliferation']['image_name'], title="Atypical melanocytic's growth");
df = pd.DataFrame(train.age_approx.value_counts())

df['name'] = df.index

alt.Chart(df).mark_bar().encode(

    x='name',

    y='age_approx',

    tooltip=["name","age_approx"]

).interactive()
fig= plt.figure(figsize=(22,6))

test["age_approx"].value_counts(normalize=True).to_frame().iplot(kind='bar',

                                                      yTitle='Percentage', 

                                                      linecolor='black', 

                                                      opacity=0.7,

                                                      color='red',

                                                      theme='pearl',

                                                      bargap=0.8,

                                                      gridcolor='white',                                                     

                                                      title='It does not exactly follow the same distribution in test though.')

plt.show()
import cv2

def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)

        image = cv2.resize(image, (256, 256))

        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(256,256))

        image[:, :, 0] = clahe.apply(image[:, :, 0])

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

    plt.subplots_adjust(wspace=0, hspace=0)

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
import matplotlib

matplotlib.font_manager._rebuild()

with plt.xkcd():



    fig = plt.figure()

    ax = fig.add_axes((0.1, 0.2, 0.8, 0.7))

    ax.spines['right'].set_color('none')

    ax.spines['top'].set_color('none')

    ax.set_xticks([])

    ax.set_yticks([])

    ax.set_ylim([-30, 10])



    data = np.ones(100)

    data[70:] -= np.arange(30)



    ax.annotate(

        'THE DAY I REALIZED\nI COULD USE APTOS METHODS\nIN OTHER COMPS',

        xy=(70, 1), arrowprops=dict(arrowstyle='->'), xytext=(15, -10))



    ax.plot(data)



    ax.set_xlabel('time')

    ax.set_ylabel('my overall sanity')

    fig.text(

        0.5, 0.05,

        '"My Mental Sanity Degrading over Time',

        ha='center')
import cv2

def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        image = cv2.resize(image, (256, 256))

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

    plt.subplots_adjust(wspace=0, hspace=0)  

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        image = cv2.resize(image, (256, 256))

        image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 256/10) ,-4 ,128)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

    plt.subplots_adjust(wspace=0, hspace=0)    

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(test_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        image = cv2.resize(image, (256, 256))

        image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 256/10) ,-4 ,128)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

    plt.subplots_adjust(wspace=0, hspace=0)    

    plt.suptitle(title)

view_images_aug(test[test['sex']=='male']['image_name'], title="Images for Male");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 10) ,-4 ,128)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

    plt.subplots_adjust(wspace=0, hspace=0)    

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def crop_image_from_gray(img,tol=7):

    if img.ndim ==2:

        mask = img>tol

        return img[np.ix_(mask.any(1),mask.any(0))]

    elif img.ndim==3:

        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

        mask = gray_img>tol

        

        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]

        if (check_shape == 0): # image is too dark so that we crop out everything,

            return img # return original image

        else:

            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]

            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]

            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]

            img = np.stack([img1,img2,img3],axis=-1)

        return img

    

def circle_crop(img, sigmaX=10):   

    """

    Create circular crop around image centre    

    """    

    

    img = crop_image_from_gray(img)    

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    

    height, width, depth = img.shape    

    

    x = int(width/2)

    y = int(height/2)

    r = np.amin((x,y))

    

    circle_img = np.zeros((height, width), np.uint8)

    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)

    img = cv2.bitwise_and(img, img, mask=circle_img)

    img = crop_image_from_gray(img)

    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)

    return img 



def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15), constrained_layout=True)

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image= circle_crop(image)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def crop_image1(img,tol=7):

    # img is image data

    # tol  is tolerance

        

    mask = img>tol

    return img[np.ix_(mask.any(1),mask.any(0))]



def crop_image_from_gray(img,tol=7):

    if img.ndim ==2:

        mask = img>tol

        return img[np.ix_(mask.any(1),mask.any(0))]

    elif img.ndim==3:

        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

        mask = gray_img>tol

        

        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]

        if (check_shape == 0): # image is too dark so that we crop out everything,

            return img # return original image

        else:

            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]

            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]

            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]

    #         print(img1.shape,img2.shape,img3.shape)

            img = np.stack([img1,img2,img3],axis=-1)

    #         print(img.shape)

        return img

    

def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image= crop_image_from_gray(image)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
fgbg = cv.createBackgroundSubtractorMOG2()

    

def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image= fgbg.apply(image)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
fgbg = cv.createBackgroundSubtractorMOG2()

    

def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        ret, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        i = im // width

        j = im % width

        axs[i,j].imshow(thresh, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        ret, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        kernel = np.ones((3, 3), np.uint8)

        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)



        # sure background area

        sure_bg = cv2.dilate(opening, kernel, iterations=3)



        # Finding sure foreground area

        dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)

        ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)



        # Finding unknown region

        sure_fg = np.uint8(sure_fg)

        unknown = cv2.subtract(sure_bg, sure_fg)

        i = im // width

        j = im % width

        axs[i,j].imshow(sure_bg, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        ret, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        kernel = np.ones((3, 3), np.uint8)

        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)



        # sure background area

        sure_bg = cv2.dilate(opening, kernel, iterations=3)



        # Finding sure foreground area

        dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)

        ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)



        # Finding unknown region

        sure_fg = np.uint8(sure_fg)

        unknown = cv2.subtract(sure_bg, sure_fg)

        ret, markers = cv2.connectedComponents(sure_fg)



        # Add one to all labels so that sure background is not 0, but 1

        markers = markers + 1



        # Now, mark the region of unknown with zero

        markers[unknown == 255] = 0

        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)



        markers = cv2.watershed(image, markers)

        image[markers == -1] = [255, 0, 0]

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        f = np.fft.fft2(image)

        fshift = np.fft.fftshift(f)

        magnitude_spectrum = 20*np.log(np.abs(fshift))



        i = im // width

        j = im % width

        axs[i,j].imshow(magnitude_spectrum, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
import albumentations as A

image_folder_path = "/kaggle/input/siim-isic-melanoma-classification/jpeg/train/"

chosen_image = cv2.imread(os.path.join(image_folder_path, "ISIC_0079038.jpg"))

albumentation_list = [A.RandomSunFlare(p=1), A.RandomFog(p=1), A.RandomBrightness(p=1),

                      A.RandomCrop(p=1,height = 512, width = 512), A.Rotate(p=1, limit=90),

                      A.RGBShift(p=1), A.RandomSnow(p=1),

                      A.HorizontalFlip(p=1), A.VerticalFlip(p=1), A.RandomContrast(limit = 0.5,p = 1),

                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]



img_matrix_list = []

bboxes_list = []

for aug_type in albumentation_list:

    img = aug_type(image = chosen_image)['image']

    img_matrix_list.append(img)



img_matrix_list.insert(0,chosen_image)    



titles_list = ["Original","RandomSunFlare","RandomFog","RandomBrightness",

               "RandomCrop","Rotate", "RGBShift", "RandomSnow","HorizontalFlip", "VerticalFlip", "RandomContrast","HSV"]



##reminder of helper function

def plot_multiple_img(img_matrix_list, title_list, ncols, main_title=""):

    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=3, ncols=ncols, squeeze=False)

    fig.suptitle(main_title, fontsize = 30)

    fig.subplots_adjust(wspace=0.3)

    fig.subplots_adjust(hspace=0.3)

    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):

        myaxes[i // ncols][i % ncols].imshow(img)

        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)

    plt.show()

    

plot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title="Different Types of Augmentations")

image_folder_path = "/kaggle/input/siim-isic-melanoma-classification/jpeg/train/"

chosen_image = cv2.imread(os.path.join(image_folder_path, "ISIC_0079038.jpg"))

albumentation_list = [A.RandomSunFlare(p=1), A.GaussNoise(p=1), A.CLAHE(p=1),

                      A.RandomRain(p=1), A.Rotate(p=1, limit=90),

                      A.RGBShift(p=1), A.RandomSnow(p=1),

                      A.HorizontalFlip(p=1), A.VerticalFlip(p=1), A.RandomContrast(limit = 0.5,p = 1),

                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]



img_matrix_list = []

bboxes_list = []

for aug_type in albumentation_list:

    img = aug_type(image = chosen_image)['image']

    img_matrix_list.append(img)



img_matrix_list.insert(0,chosen_image)    



titles_list = ["Original","RandomSunFlare","GaussNoise","CLAHE",

               "RandomRain","Rotate", "RGBShift", "RandomSnow","HorizontalFlip", "VerticalFlip", "RandomContrast","HSV"]



##reminder of helper function

def plot_multiple_img(img_matrix_list, title_list, ncols, main_title=""):

    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=3, ncols=ncols, squeeze=False)

    fig.suptitle(main_title, fontsize = 30)

    fig.subplots_adjust(wspace=0.3)

    fig.subplots_adjust(hspace=0.3)

    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):

        myaxes[i // ncols][i % ncols].imshow(img)

        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)

    plt.show()

    

plot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title="Different Types of Augmentations")

image_folder_path = "/kaggle/input/siim-isic-melanoma-classification/jpeg/train/"

chosen_image = cv2.imread(os.path.join(image_folder_path, "ISIC_0079038.jpg"))

albumentation_list = [A.RandomSunFlare(p=0.8), A.GaussNoise(p=0.8), A.CLAHE(p=0.9),

                      A.RandomRain(p=1), A.Rotate(p=1, limit=90),

                      A.RGBShift(p=1), A.RandomSnow(p=1),

                      A.HorizontalFlip(p=1), A.VerticalFlip(p=0.8), A.RandomContrast(limit = 0.5,p = 1),

                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]



img_matrix_list = []

bboxes_list = []

for aug_type in albumentation_list:

    img = aug_type(image = chosen_image)['image']

    img_matrix_list.append(img)



img_matrix_list.insert(0,chosen_image)    



titles_list = ["Original","RandomSunFlare","GaussNoise","CLAHE",

               "RandomRain","Rotate", "RGBShift", "RandomSnow","HorizontalFlip", "VerticalFlip", "RandomContrast","HSV"]



##reminder of helper function

def plot_multiple_img(img_matrix_list, title_list, ncols, main_title=""):

    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=3, ncols=ncols, squeeze=False)

    fig.suptitle(main_title, fontsize = 30)

    fig.subplots_adjust(wspace=0.3)

    fig.subplots_adjust(hspace=0.3)

    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):

        myaxes[i // ncols][i % ncols].imshow(img)

        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)

    plt.show()

    

plot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title="Different Types of Augmentations")

def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        kernel = np.ones((5,5), np.uint8) 

  

        # The first parameter is the original image, 

        # kernel is the matrix with which image is  

        # convolved and third parameter is the number  

        # of iterations, which will determine how much  

        # you want to erode/dilate a given image.  

        img_erosion = cv2.erode(image, kernel, iterations=1) 

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's Erosion");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        kernel = np.ones((5,5), np.uint8) 

    

        img_erosion = cv2.dilate(image, kernel, iterations=1) 

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's Erosion");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        kernel = np.ones((5,5), np.uint8) 

  

        img_erosion = cv2.erode(image, kernel, iterations=1) 

        img_erosion = cv2.dilate(image, kernel, iterations=1) 

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's Erosion");
image_folder_path = "/kaggle/input/siim-isic-melanoma-classification/jpeg/train/"

chosen_image = cv2.imread(os.path.join(image_folder_path, "ISIC_0079038.jpg"))

image = cv2.cvtColor(chosen_image, cv2.COLOR_BGR2RGB)

image = cv2.resize(image, (256, 256))

kernel = np.ones((5,5), np.uint8) 

  

image = cv2.erode(image, kernel, iterations=1) 

albumentation_list = [A.RandomSunFlare(p=0.8), A.GaussNoise(p=0.8), A.CLAHE(p=0.9),

                      A.RandomRain(p=1), A.Rotate(p=1, limit=90),

                      A.RGBShift(p=1), A.RandomSnow(p=1),

                      A.HorizontalFlip(p=1), A.VerticalFlip(p=0.8), A.RandomContrast(limit = 0.5,p = 1),

                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]



img_matrix_list = []

bboxes_list = []

for aug_type in albumentation_list:

    img = aug_type(image = chosen_image)['image']

    img_matrix_list.append(img)



img_matrix_list.insert(0,chosen_image)    



titles_list = ["Original","RandomSunFlare","GaussNoise","CLAHE",

               "RandomRain","Rotate", "RGBShift", "RandomSnow","HorizontalFlip", "VerticalFlip", "RandomContrast","HSV"]



##reminder of helper function

def plot_multiple_img(img_matrix_list, title_list, ncols, main_title=""):

    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=3, ncols=ncols, squeeze=False)

    fig.suptitle(main_title, fontsize = 30)

    fig.subplots_adjust(wspace=0.3)

    fig.subplots_adjust(hspace=0.3)

    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):

        myaxes[i // ncols][i % ncols].imshow(img)

        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)

    plt.show()

    

plot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title="Different Types of Augmentations")

image_folder_path = "/kaggle/input/siim-isic-melanoma-classification/jpeg/train/"

chosen_image = cv2.imread(os.path.join(image_folder_path, "ISIC_0079038.jpg"))

image = cv2.cvtColor(chosen_image, cv2.COLOR_BGR2RGB)

image = cv2.resize(image, (256, 256))

kernel = np.ones((5,5), np.uint8) 

  

image = cv2.dilate(image, kernel, iterations=1) 

albumentation_list = [A.RandomSunFlare(p=0.8), A.GaussNoise(p=0.8), A.CLAHE(p=0.9),

                      A.RandomRain(p=1), A.Rotate(p=1, limit=90),

                      A.RGBShift(p=1), A.RandomSnow(p=1),

                      A.HorizontalFlip(p=1), A.VerticalFlip(p=0.8), A.RandomContrast(limit = 0.5,p = 1),

                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]



img_matrix_list = []

bboxes_list = []

for aug_type in albumentation_list:

    img = aug_type(image = chosen_image)['image']

    img_matrix_list.append(img)



img_matrix_list.insert(0,chosen_image)    



titles_list = ["Original","RandomSunFlare","GaussNoise","CLAHE",

               "RandomRain","Rotate", "RGBShift", "RandomSnow","HorizontalFlip", "VerticalFlip", "RandomContrast","HSV"]



##reminder of helper function

def plot_multiple_img(img_matrix_list, title_list, ncols, main_title=""):

    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=3, ncols=ncols, squeeze=False)

    fig.suptitle(main_title, fontsize = 30)

    fig.subplots_adjust(wspace=0.3)

    fig.subplots_adjust(hspace=0.3)

    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):

        myaxes[i // ncols][i % ncols].imshow(img)

        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)

    plt.show()

    

plot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title="Different Types of Augmentations")

image_folder_path = "/kaggle/input/siim-isic-melanoma-classification/jpeg/train/"

chosen_image = cv2.imread(os.path.join(image_folder_path, "ISIC_0079038.jpg"))

image = cv2.cvtColor(chosen_image, cv2.COLOR_BGR2RGB)

image = cv2.resize(image, (256, 256))

kernel = np.ones((5,5), np.uint8) 

  

image = cv2.dilate(image, kernel, iterations=1) 

image = cv2.erode(image, kernel, iterations=1) 



albumentation_list = [A.RandomSunFlare(p=0.8), A.GaussNoise(p=0.8), A.CLAHE(p=0.9),

                      A.RandomRain(p=1), A.Rotate(p=1, limit=90),

                      A.RGBShift(p=1), A.RandomSnow(p=1),

                      A.HorizontalFlip(p=1), A.VerticalFlip(p=0.8), A.RandomContrast(limit = 0.5,p = 1),

                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]



img_matrix_list = []

bboxes_list = []

for aug_type in albumentation_list:

    img = aug_type(image = chosen_image)['image']

    img_matrix_list.append(img)



img_matrix_list.insert(0,chosen_image)    



titles_list = ["Original","RandomSunFlare","GaussNoise","CLAHE",

               "RandomRain","Rotate", "RGBShift", "RandomSnow","HorizontalFlip", "VerticalFlip", "RandomContrast","HSV"]



##reminder of helper function

def plot_multiple_img(img_matrix_list, title_list, ncols, main_title=""):

    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=3, ncols=ncols, squeeze=False)

    fig.suptitle(main_title, fontsize = 30)

    fig.subplots_adjust(wspace=0.3)

    fig.subplots_adjust(hspace=0.3)

    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):

        myaxes[i // ncols][i % ncols].imshow(img)

        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)

    plt.show()

    

plot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title="Different Types of Augmentations")

import pywt

def crop_image_from_gray(img,tol=7):

    if img.ndim ==2:

        mask = img>tol

        return img[np.ix_(mask.any(1),mask.any(0))]

    elif img.ndim==3:

        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

        mask = gray_img>tol

        

        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]

        if (check_shape == 0): # image is too dark so that we crop out everything,

            return img # return original image

        else:

            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]

            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]

            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]

            img = np.stack([img1,img2,img3],axis=-1)

        return img

    

def circle_crop(img, sigmaX=10):   

    """

    Create circular crop around image centre    

    """    

    

    img = crop_image_from_gray(img)    

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    

    height, width, depth = img.shape    

    

    x = int(width/2)

    y = int(height/2)

    r = np.amin((x,y))

    

    circle_img = np.zeros((height, width), np.uint8)

    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)

    img = cv2.bitwise_and(img, img, mask=circle_img)

    img = crop_image_from_gray(img)

    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)

    return img 



def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15), constrained_layout=True)

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image= circle_crop(image)

        coeffs = pywt.dwt2(image, 'bior1.3')

        IM1, (IM2, IM3, IM4) = coeffs

        image = IM2

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
import pywt

def crop_image_from_gray(img,tol=7):

    if img.ndim ==2:

        mask = img>tol

        return img[np.ix_(mask.any(1),mask.any(0))]

    elif img.ndim==3:

        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

        mask = gray_img>tol

        

        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]

        if (check_shape == 0): # image is too dark so that we crop out everything,

            return img # return original image

        else:

            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]

            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]

            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]

            img = np.stack([img1,img2,img3],axis=-1)

        return img

    

def circle_crop(img, sigmaX=10):   

    """

    Create circular crop around image centre    

    """    

    

    img = crop_image_from_gray(img)    

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    

    height, width, depth = img.shape    

    

    x = int(width/2)

    y = int(height/2)

    r = np.amin((x,y))

    

    circle_img = np.zeros((height, width), np.uint8)

    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)

    img = cv2.bitwise_and(img, img, mask=circle_img)

    img = crop_image_from_gray(img)

    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)

    return img 



def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15), constrained_layout=True)

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image= circle_crop(image)

        coeffs = pywt.dwt2(image, 'bior1.3')

        IM1, (IM2, IM3, IM4) = coeffs

        image = IM3

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.gray) 

        axs[i,j].axis('off')

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15), constrained_layout=True)

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image= circle_crop(image)

        circles = cv2.HoughCircles(imagee,cv2.HOUGH_GRADIENT,1,20,

                            param1=50,param2=30,minRadius=0,maxRadius=0)



        image = np.uint16(np.around(circles))

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.gray) 

        axs[i,j].axis('off')

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15), constrained_layout=True)

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image= circle_crop(image)

        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

        edges = cv2.Canny(gray,50,150,apertureSize = 3)



        lines = cv2.HoughLines(edges,1,np.pi/180,200)

        for rho,theta in lines[0]:

            a = np.cos(theta)

            b = np.sin(theta)

            x0 = a*rho

            y0 = b*rho

            x1 = int(x0 + 1000*(-b))

            y1 = int(y0 + 1000*(a))

            x2 = int(x0 - 1000*(-b))

            y2 = int(y0 - 1000*(a))



        image = cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.gray) 

        axs[i,j].axis('off')

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's growth");
X_train, X_val = train_test_split(train, test_size=0.2, random_state=42)

X_train['image_name'] = X_train['image_name'].apply(lambda x: x + '.jpg')

X_val['image_name'] = X_val['image_name'].apply(lambda x: x + '.jpg')

test['image_name'] = test['image_name'].apply(lambda x: x + '.jpg')

X_train['target'] = X_train['target'].apply(lambda x: str(x))

X_val['target'] = X_val['target'].apply(lambda x: str(x))
from keras.applications import ResNet50 as model

from PIL import Image

model = model(weights='imagenet')

model.compile(

    'Adam',

    loss='sparse_categorical_crossentropy',

    metrics=['accuracy'],

)
print(f"Train set is {train.shape[0] / test.shape[0]} times bigger than test set.")
from sklearn.model_selection import RepeatedKFold

splitter = RepeatedKFold(n_splits=3, n_repeats=1, random_state=0)
partitions = []



for train_idx, test_idx in splitter.split(train.index.values):

    partition = {}

    partition["train"] = train.image_name.values[train_idx]

    partition["validation"] = train.image_name.values[test_idx]

    partitions.append(partition)

    print("TRAIN:", train_idx, "TEST:", test_idx)

    print("TRAIN:", len(train_idx), "TEST:", len(test_idx))
class Config:

    BATCH_SIZE = 8

    EPOCHS = 40

    WARMUP_EPOCHS = 2

    LEARNING_RATE = 1e-4

    WARMUP_LEARNING_RATE = 1e-3

    HEIGHT = 224

    WIDTH = 224

    CANAL = 3

    N_CLASSES = train['target'].nunique()

    ES_PATIENCE = 5

    RLROP_PATIENCE = 3

    DECAY_DROP = 0.5
train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, 

                                 rotation_range=360,

                                 horizontal_flip=True,

                                 vertical_flip=True)



train_generator=train_datagen.flow_from_dataframe(

    dataframe=X_train,

    directory='../input/siim-isic-melanoma-classification/jpeg/train/',

    x_col="image_name",

    y_col="target",

    class_mode="raw",

    batch_size=Config.BATCH_SIZE,

    target_size=(Config.HEIGHT, Config.WIDTH),

    seed=0)



validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)



valid_generator=validation_datagen.flow_from_dataframe(

    dataframe=X_val,

    directory='../input/siim-isic-melanoma-classification/jpeg/train/',

    x_col="image_name",

    y_col="target",

    class_mode="raw", 

    batch_size=Config.BATCH_SIZE,   

    target_size=(Config.HEIGHT, Config.WIDTH),

    seed=0)



test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)



test_generator = test_datagen.flow_from_dataframe(  

        dataframe=test,

        directory = '../input/siim-isic-melanoma-classification/jpeg/test/',

        x_col="image_name",

        batch_size=1,

        class_mode=None,

        shuffle=False,

        target_size=(Config.HEIGHT, Config.WIDTH),

        seed=0)
"""


STEP_SIZE_TRAIN = train_generator.n//64

STEP_SIZE_VALID = valid_generator.n//64

history = model.fit_generator(generator=train_generator,

                                    steps_per_epoch=STEP_SIZE_TRAIN,

                                    validation_data=valid_generator,

                                    validation_steps=STEP_SIZE_VALID,

                                    epochs=1,

                                    verbose=1).history

"""                                    
import random

def sp_noise(image,prob):

    '''

    Add salt and pepper noise to image

    prob: Probability of the noise

    '''

    output = np.zeros(image.shape,np.uint8)

    thres = 1 - prob 

    for i in range(image.shape[0]):

        for j in range(image.shape[1]):

            rdn = random.random()

            if rdn < prob:

                output[i][j] = 0

            elif rdn > thres:

                output[i][j] = 255

            else:

                output[i][j] = image[i][j]

    return output



def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image = sp_noise(image, 0.192)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='lentigo NOS']['image_name'], title="Lentigo NOS's Erosion");
import random

def sp_noise(image,prob):

    '''

    Add salt and pepper noise to image

    prob: Probability of the noise

    '''

    output = np.zeros(image.shape,np.uint8)

    thres = 1 - prob 

    for i in range(image.shape[0]):

        for j in range(image.shape[1]):

            rdn = random.random()

            if rdn < prob:

                output[i][j] = 0

            elif rdn > thres:

                output[i][j] = 255

            else:

                output[i][j] = image[i][j]

    return output



def view_images_aug(images, title = '', aug = None):

    width = 6

    height = 5

    fig, axs = plt.subplots(height, width, figsize=(15,15))

    for im in range(0, height * width):  

        data = pydicom.read_file(os.path.join(train_images_dir, list(images)[im]+ '.dcm'))

        image = data.pixel_array

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image = cv2.resize(image, (256, 256))

        image = sp_noise(image, 0.192)

        i = im // width

        j = im % width

        axs[i,j].imshow(image, cmap=plt.cm.bone) 

        axs[i,j].axis('off')

        

    plt.suptitle(title)

view_images_aug(train[train['diagnosis']=='unknown']['image_name'], title="Lentigo NOS's Erosion");
YouTubeVideo("bQLphecl-1A", height=500, width=800)
YouTubeVideo("=-O3fLMg6qwQ", height=500, width=800)