import pandas as pd



trainLabels = pd.read_csv("../input/trainLabels.csv")

trainLabels.head()
from PIL import Image

from keras.preprocessing import image

import os

import numpy as np



# resize the image to (256, 256)

img_rows, img_cols = 256, 256



listing = os.listdir("../input") 

listing.remove("trainLabels.csv")



immatrix = []

imlabel = []



for file in listing:

    base = os.path.basename("../input/" + file)

    fileName = os.path.splitext(base)[0]

    imlabel.append(trainLabels.loc[trainLabels.image==fileName, 'level'].values[0])

    im = Image.open("../input/" + file)

    img = np.array(im.resize((img_rows,img_cols)))

    

    # convert to green channel only

    img[:,:,[0,2]] = 0

    immatrix.append(img)
im = Image.fromarray(immatrix[1],'RGB')

print("level:",imlabel[1])

im
import random



# define transformation methods

def horizontal_flip(image_array):

    return image_array[:, ::-1]



def vertical_flip(image_array):

    return image_array[::-1,:]



def random_transform(image_array):

    if random.random() < 0.5:

        return vertical_flip(image_array)

    else:

        return horizontal_flip(image_array)
im = Image.fromarray(vertical_flip(immatrix[1]),'RGB')

im
length = len(immatrix)

for i in range(length):

    if random.random() < 0.1:

        immatrix.append(random_transform(immatrix[i]))

        imlabel.append(imlabel[i])

        

print("Size of image array before augmentation: ", length)

print("Size fo image array after augmentation: ", len(immatrix))
from sklearn.utils import shuffle



data,label = shuffle(immatrix, imlabel, random_state=42)

train_data = [data,label]
import matplotlib.pyplot as plt



plt.hist(label)

plt.show()
from sklearn.model_selection import train_test_split



x_train, x_test, y_train, y_test = train_test_split(train_data[0], train_data[1], test_size = 0.1, random_state = 42)



print(np.array(x_train).shape)

print(np.array(y_train).shape)
from keras.utils import np_utils



y_train = np_utils.to_categorical(np.array(y_train), 5)

y_test = np_utils.to_categorical(np.array(y_test), 5)



x_train = np.array(x_train).astype("float32")/255.

x_test = np.array(x_test).astype("float32")/255.



print(np.array(y_train).shape)
import keras

from keras.models import Sequential

from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization



model = Sequential()



model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train[0].shape))

model.add(Conv2D(32, (3, 3), activation='relu'))

model.add(MaxPooling2D())

model.add(Dropout(0.25))



model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))

model.add(Conv2D(64, (3, 3), activation='relu'))

model.add(MaxPooling2D())

model.add(Dropout(0.25))



model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))

model.add(Conv2D(64, (3, 3), activation='relu'))

model.add(MaxPooling2D())

model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(512, activation='relu'))

model.add(Dropout(0.5))

model.add(Dense(activation='softmax', units=5))



model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.SGD(lr=0.0001, momentum=0.9), metrics=["accuracy"])
model.summary()
model.fit(x_train, y_train, batch_size = 64, epochs=10, shuffle=True, verbose=2)
predictions = model.predict(x_test)

predictions
score = model.evaluate(x_test, y_test, verbose=0)

print(score)