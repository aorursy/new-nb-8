# This Python 3 environment comes with many helpful analytics libraries installed

# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python

# For example, here's several helpful packages to load in 



import numpy as np # linear algebra

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)



# Input data files are available in the "../input/" directory.

# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory



import os

import glob



import pydicom



print(os.listdir("../input/siim-acr-pneumothorax-segmentation"))

print()

print(os.listdir("../input/siim-acr-pneumothorax-segmentation/sample images"))

# Any results you write to the current directory are saved as output.



from matplotlib import cm

from matplotlib import pyplot as plt



from keras.models import Model

from keras.layers import Input

from keras.layers.convolutional import Conv2D, Conv2DTranspose

from keras.layers.pooling import MaxPooling2D

from keras.layers.merge import concatenate

from keras import backend as K



import tensorflow as tf



from tqdm import tqdm_notebook



import sys

sys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')



from mask_functions import rle2mask
def show_dcm_info(dataset):

    print("Filename.........:", file_path)

    print("Storage type.....:", dataset.SOPClassUID)

    print()



    pat_name = dataset.PatientName

    display_name = pat_name.family_name + ", " + pat_name.given_name

    print("Patient's name......:", display_name)

    print("Patient id..........:", dataset.PatientID)

    print("Patient's Age.......:", dataset.PatientAge)

    print("Patient's Sex.......:", dataset.PatientSex)

    print("Modality............:", dataset.Modality)

    print("Body Part Examined..:", dataset.BodyPartExamined)

    print("View Position.......:", dataset.ViewPosition)

    

    if 'PixelData' in dataset:

        rows = int(dataset.Rows)

        cols = int(dataset.Columns)

        print("Image size.......: {rows:d} x {cols:d}, {size:d} bytes".format(

            rows=rows, cols=cols, size=len(dataset.PixelData)))

        if 'PixelSpacing' in dataset:

            print("Pixel spacing....:", dataset.PixelSpacing)



def plot_pixel_array(dataset, figsize=(10,10)):

    plt.figure(figsize=figsize)

    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)

    plt.show()

for file_path in glob.glob('../input/siim-acr-pneumothorax-segmentation/sample images/*.dcm'):

    dataset = pydicom.dcmread(file_path)

    show_dcm_info(dataset)

    plot_pixel_array(dataset)

    break # Comment this out to see all
num_img = len(glob.glob('../input/siim-acr-pneumothorax-segmentation/sample images/*.dcm'))

fig, ax = plt.subplots(nrows=1, ncols=num_img, sharey=True, figsize=(num_img*10,10))

for q, file_path in enumerate(glob.glob('../input/siim-acr-pneumothorax-segmentation/sample images/*.dcm')):

    dataset = pydicom.dcmread(file_path)

    #show_dcm_info(dataset)

    

    ax[q].imshow(dataset.pixel_array, cmap=plt.cm.bone)
start = 5   # Starting index of images

num_img = 4 # Total number of images to show



fig, ax = plt.subplots(nrows=1, ncols=num_img, sharey=True, figsize=(num_img*10,10))

for q, file_path in enumerate(glob.glob('../input/siim-acr-pneumothorax-segmentation/sample images/*.dcm')[start:start+num_img]):

    dataset = pydicom.dcmread(file_path)

    #show_dcm_info(dataset)

    

    ax[q].imshow(dataset.pixel_array, cmap=plt.cm.bone)

df = pd.read_csv('../input/siim-acr-pneumothorax-segmentation/sample images/train-rle-sample.csv', header=None, index_col=0)



fig, ax = plt.subplots(nrows=1, ncols=num_img, sharey=True, figsize=(num_img*10,10))

for q, file_path in enumerate(glob.glob('../input/siim-acr-pneumothorax-segmentation/sample images/*.dcm')[start:start+num_img]):

    dataset = pydicom.dcmread(file_path)

    #print(file_path.split('/')[-1][:-4])

    ax[q].imshow(dataset.pixel_array, cmap=plt.cm.bone)

    if df.loc[file_path.split('/')[-1][:-4],1] != '-1':

        mask = rle2mask(df.loc[file_path.split('/')[-1][:-4],1], 1024, 1024).T

        ax[q].set_title('See Marker')

        ax[q].imshow(mask, alpha=0.3, cmap="Reds")

    else:

        ax[q].set_title('Nothing to see')

train_glob = '../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/dicom-images-train/*/*/*.dcm'

test_glob = '../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/dicom-images-test/*/*/*.dcm'

train_fns = sorted(glob.glob(train_glob))[:5000]

test_fns = sorted(glob.glob(test_glob))[:5000]

df_full = pd.read_csv('../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/train-rle.csv', index_col='ImageId')
df_full.columns
im_height = 1024

im_width = 1024

im_chan = 1

# Get train images and masks

X_train = np.zeros((len(train_fns), im_height, im_width, im_chan), dtype=np.uint8)

Y_train = np.zeros((len(train_fns), im_height, im_width, 1), dtype=np.bool)

print('Getting train images and masks ... ')

sys.stdout.flush()

for n, _id in tqdm_notebook(enumerate(train_fns), total=len(train_fns)):

    dataset = pydicom.read_file(_id)

    X_train[n] = np.expand_dims(dataset.pixel_array, axis=2)

    try:

        if '-1' in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:

            Y_train[n] = np.zeros((1024, 1024, 1))

        else:

            if type(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']) == str:

                Y_train[n] = np.expand_dims(rle2mask(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels'], 1024, 1024), axis=2)

            else:

                Y_train[n] = np.zeros((1024, 1024, 1))

                for x in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:

                    Y_train[n] =  Y_train[n] + np.expand_dims(rle2mask(x, 1024, 1024), axis=2)

    except KeyError:

        print(f"Key {_id.split('/')[-1][:-4]} without mask, assuming healthy patient.")

        Y_train[n] = np.zeros((1024, 1024, 1)) # Assume missing masks are empty masks.



print('Done!')
im_height = 128

im_width = 128

X_train = X_train.reshape((-1, im_height, im_width, 1))

Y_train = Y_train.reshape((-1, im_height, im_width, 1))
def dice_coef(y_true, y_pred, smooth=1):

    y_true_f = K.flatten(y_true)

    y_pred_f = K.flatten(y_pred)

    intersection = K.sum(y_true_f * y_pred_f)

    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
inputs = Input((None, None, im_chan))



c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)

c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)

p1 = MaxPooling2D((2, 2)) (c1)



c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)

c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)

p2 = MaxPooling2D((2, 2)) (c2)



c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)

c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)

p3 = MaxPooling2D((2, 2)) (c3)



c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)

c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)

p4 = MaxPooling2D(pool_size=(2, 2)) (c4)



c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)

c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)

p5 = MaxPooling2D(pool_size=(2, 2)) (c5)



c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)

c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)



u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)

u6 = concatenate([u6, c5])

c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)

c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)



u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)

u71 = concatenate([u71, c4])

c71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)

c61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)



u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)

u7 = concatenate([u7, c3])

c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)

c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)



u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)

u8 = concatenate([u8, c2])

c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)

c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)



u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)

u9 = concatenate([u9, c1], axis=3)

c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)

c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)



outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)



model = Model(inputs=[inputs], outputs=[outputs])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])

model.summary()
model.fit(X_train, Y_train, validation_split=.2, batch_size=512, epochs=2)