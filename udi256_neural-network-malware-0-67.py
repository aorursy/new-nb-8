# IMPORT LIBRARIES

import pandas as pd, numpy as np, os, gc



# LOAD AND FREQUENCY-ENCODE

FE = ['EngineVersion','AppVersion','AvSigVersion','Census_OSVersion']

# LOAD AND ONE-HOT-ENCODE

OHE = [ 'RtpStateBitfield','IsSxsPassiveMode','DefaultBrowsersIdentifier',

        'AVProductStatesIdentifier','AVProductsInstalled', 'AVProductsEnabled',

        'CountryIdentifier', 'CityIdentifier', 

        'GeoNameIdentifier', 'LocaleEnglishNameIdentifier',

        'Processor', 'OsBuild', 'OsSuite',

        'SmartScreen','Census_MDC2FormFactor',

        'Census_OEMNameIdentifier', 

        'Census_ProcessorCoreCount',

        'Census_ProcessorModelIdentifier', 

        'Census_PrimaryDiskTotalCapacity', 'Census_PrimaryDiskTypeName',

        'Census_HasOpticalDiskDrive',

        'Census_TotalPhysicalRAM', 'Census_ChassisTypeName',

        'Census_InternalPrimaryDiagonalDisplaySizeInInches',

        'Census_InternalPrimaryDisplayResolutionHorizontal',

        'Census_InternalPrimaryDisplayResolutionVertical',

        'Census_PowerPlatformRoleName', 'Census_InternalBatteryType',

        'Census_InternalBatteryNumberOfCharges',

        'Census_OSEdition', 'Census_OSInstallLanguageIdentifier',

        'Census_GenuineStateName','Census_ActivationChannel',

        'Census_FirmwareManufacturerIdentifier',

        'Census_IsTouchEnabled', 'Census_IsPenCapable',

        'Census_IsAlwaysOnAlwaysConnectedCapable', 'Wdft_IsGamer',

        'Wdft_RegionIdentifier']



# LOAD ALL AS CATEGORIES

dtypes = {}

for x in FE+OHE: dtypes[x] = 'category'

dtypes['MachineIdentifier'] = 'str'

dtypes['HasDetections'] = 'int8'



# LOAD CSV FILE

df_train = pd.read_csv('../input/train.csv', usecols=dtypes.keys(), dtype=dtypes)

print ('Loaded',len(df_train),'rows of TRAIN.CSV!')



full_df_train=df_train



# DOWNSAMPLE

#sm = 2000000

sm=2000

df_train = df_train.sample(sm)

print ('Only using',sm,'rows to train and validate')

x=gc.collect()
print(df_train['Census_HasOpticalDiskDrive'].value_counts())

print(df_train['HasDetections'].value_counts())

print(full_df_train['HasDetections'].value_counts())

import statistics

print(statistics.stdev(df_train['HasDetections']))

print(statistics.stdev([0,0,1,1,0,0,1,1]*100))
import math



# CHECK FOR NAN

def nan_check(x):

    if isinstance(x,float):

        if math.isnan(x):

            return True

    return False



# FREQUENCY ENCODING

def encode_FE(df,col,verbose=1):

    d = df[col].value_counts(dropna=False)

    n = col+"_FE"

    df[n] = df[col].map(d)/d.max()

    if verbose==1:

        print('FE encoded',col)

    return [n]



# ONE-HOT-ENCODE ALL CATEGORY VALUES THAT COMPRISE MORE THAN

# "FILTER" PERCENT OF TOTAL DATA AND HAS SIGNIFICANCE GREATER THAN "ZVALUE"

def encode_OHE(df, col, filter, zvalue, tar='HasDetections', m=0.5, verbose=1):

    cv = df[col].value_counts(dropna=False)

    cvd = cv.to_dict()

    vals = len(cv)

    th = filter * len(df)

    sd = zvalue * 0.5/ math.sqrt(th)

    #print(sd)

    n = []; ct = 0; d = {}

    for x in cv.index:

        try:

            if cv[x]<th: break

            sd = zvalue * 0.5/ math.sqrt(cv[x])

        except:

            if cvd[x]<th: break

            sd = zvalue * 0.5/ math.sqrt(cvd[x])

        if nan_check(x): r = df[df[col].isna()][tar].mean()

        else: r = df[df[col]==x][tar].mean()

        if abs(r-m)>sd:

            nm = col+'_BE_'+str(x)

            if nan_check(x): df[nm] = (df[col].isna()).astype('int8')

            else: df[nm] = (df[col]==x).astype('int8')

            n.append(nm)

            d[x] = 1

        ct += 1

        if (ct+1)>=vals: break

    if verbose==1:

        print('OHE encoded',col,'- Created',len(d),'booleans')

    return [n,d]



# ONE-HOT-ENCODING from dictionary

def encode_OHE_test(df,col,dt):

    n = []

    for x in dt: 

        n += encode_BE(df,col,x)

    return n



# BOOLEAN ENCODING

def encode_BE(df,col,val):

    n = col+"_BE_"+str(val)

    if nan_check(val):

        df[n] = df[col].isna()

    else:

        df[n] = df[col]==val

    df[n] = df[n].astype('int8')

    return [n]
cols = []; dd = []



# ENCODE NEW

for x in FE:

    cols += encode_FE(df_train,x)

for x in OHE:

    tmp = encode_OHE(df_train,x,0.005,5)

    cols += tmp[0]; dd.append(tmp[1])

print('Encoded',len(cols),'new variables')



# REMOVE OLD

for x in FE+OHE:

    del df_train[x]

print('Removed original',len(FE+OHE),'variables')

x = gc.collect()
from keras import callbacks

from sklearn.metrics import roc_auc_score



class printAUC(callbacks.Callback):

    def __init__(self, X_train, y_train):

        super(printAUC, self).__init__()

        self.bestAUC = 0

        self.X_train = X_train

        self.y_train = y_train

        

    def on_epoch_end(self, epoch, logs={}):

        pred = self.model.predict(np.array(self.X_train))

        auc = roc_auc_score(self.y_train, pred)

        print("Train AUC: " + str(auc))

        pred = self.model.predict(self.validation_data[0])

        auc = roc_auc_score(self.validation_data[1], pred)

        print ("Validation AUC: " + str(auc))

        if (self.bestAUC < auc) :

            self.bestAUC = auc

            self.model.save("bestNet.h5", overwrite=True)

        return
print (len(cols))
from sklearn.model_selection import train_test_split

from keras.models import Sequential

from keras.layers import Dense, Dropout, BatchNormalization, Activation

from keras.callbacks import LearningRateScheduler

from keras.optimizers import Adam



#SPLIT TRAIN AND VALIDATION SET

X_train, X_val, Y_train, Y_val = train_test_split(

    df_train[cols], df_train['HasDetections'], test_size = 0.5)



# BUILD MODEL

model = Sequential()

model.add(Dense(100,input_dim=len(cols)))

model.add(Dropout(0.4))

model.add(BatchNormalization())

model.add(Activation('relu'))

model.add(Dense(100))

model.add(Dropout(0.4))

model.add(BatchNormalization())

model.add(Activation('relu'))

model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer=Adam(lr=0.01), loss="binary_crossentropy", metrics=["accuracy"])

annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)



# TRAIN MODEL

model.fit(X_train,Y_train, batch_size=32, epochs = 20, callbacks=[annealer,

          printAUC(X_train, Y_train)], validation_data = (X_val,Y_val), verbose=2)
del df_train

del X_train, X_val, Y_train, Y_val

x = gc.collect()



# LOAD BEST SAVED NET

from keras.models import load_model

model = load_model('bestNet.h5')



pred = np.zeros((7853253,1))

id = 1

chunksize = 2000000

for df_test in pd.read_csv('../input/test.csv', 

            chunksize = chunksize, usecols=list(dtypes.keys())[0:-1], dtype=dtypes):

    print ('Loaded',len(df_test),'rows of TEST.CSV!')

    # ENCODE TEST

    cols = []

    for x in FE:

        cols += encode_FE(df_test,x,verbose=0)

    for x in range(len(OHE)):

        cols += encode_OHE_test(df_test,OHE[x],dd[x])

    # PREDICT TEST

    end = (id)*chunksize

    if end>7853253: end = 7853253

    pred[(id-1)*chunksize:end] = model.predict(df_test[cols])

    print('  encoded and predicted part',id)

    id += 1
# SUBMIT TO KAGGLE

df_test = pd.read_csv('../input/test.csv', usecols=['MachineIdentifier'])

df_test['HasDetections'] = pred

df_test.to_csv('submission.csv', index=False)