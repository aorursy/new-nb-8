import pandas as pd

import numpy as np

import re

import warnings

warnings.filterwarnings("ignore")

import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.feature_extraction.text import CountVectorizer

from sklearn.feature_extraction.text import TfidfVectorizer

from wordcloud import WordCloud

from nltk.corpus import stopwords

from nltk.tokenize import word_tokenize

from nltk.stem.snowball import SnowballStemmer

from sklearn.model_selection import train_test_split

from sklearn.multiclass import OneVsRestClassifier

from sklearn.linear_model import SGDClassifier

from sklearn.linear_model import LogisticRegression

from sklearn import metrics

from sklearn.metrics import f1_score,precision_score,recall_score
df = pd.read_csv("/kaggle/input/facebook-recruiting-iii-keyword-extraction/Train.zip")

df.head()
print("Dataframe shape : ", df.shape)
df = df.iloc[:10000, :]

print("Shape of Dataframe after subsetting : ", df.shape)
duplicate_pairs = df.sort_values('Title', ascending=False).duplicated('Title')

print("Total number of duplicate questions : ", duplicate_pairs.sum())

df = df[~duplicate_pairs]

print("Dataframe shape after duplicate removal : ", df.shape)
df["tag_count"] = df["Tags"].apply(lambda x : len(x.split()))
df["tag_count"].value_counts()
print( "Maximum number of tags in a question: ", df["tag_count"].max())

print( "Minimum number of tags in a question: ", df["tag_count"].min())

print( "Average number of tags in a question: ", df["tag_count"].mean())
sns.countplot(df["tag_count"])

plt.title("Number of tags in questions ")

plt.xlabel("Number of Tags")

plt.ylabel("Frequency")
vectorizer = CountVectorizer(tokenizer = lambda x: x.split())

tag_bow = vectorizer.fit_transform(df['Tags'])
print("Number of questions :", tag_bow.shape[0])

print("Number of unique tags :", tag_bow.shape[1])
tags = vectorizer.get_feature_names()

print("Few tags :", tags[:10])
freq = tag_bow.sum(axis=0).A1

tag_to_count_map = dict(zip(tags, freq))
list = []

for key, value in tag_to_count_map.items():

  list.append([key, value]) 
tag_df = pd.DataFrame(list, columns=['Tags', 'Counts'])

tag_df.head()
tag_df_sorted = tag_df.sort_values(['Counts'], ascending=False)

plt.plot(tag_df_sorted['Counts'].values)

plt.grid()

plt.title("Distribution of frequency of tags based on appeareance")

plt.xlabel("Tag numbers for most frequent tags")

plt.ylabel("Frequency")
plt.plot(tag_df_sorted['Counts'][0:100].values)

plt.grid()

plt.title("Top 100 tags : Distribution of frequency of tags based on appeareance")

plt.xlabel("Tag numbers for most frequent tags")

plt.ylabel("Frequency")
plt.plot(tag_df_sorted['Counts'][0:100].values)

plt.scatter(x=np.arange(0,100,5), y=tag_df_sorted['Counts'][0:100:5], c='g', label="quantiles with 0.05 intervals")

plt.scatter(x=np.arange(0,100,25), y=tag_df_sorted['Counts'][0:100:25], c='r', label = "quantiles with 0.25 intervals")

for x,y in zip(np.arange(0,100,25), tag_df_sorted['Counts'][0:100:25]):

    plt.annotate(s="({} , {})".format(x,y), xy=(x,y), xytext=(x-0.01, y+30))



plt.title('first 100 tags: Distribution of frequency of tags based on appeareance')

plt.grid()

plt.xlabel("Tag numbers for most frequent tags")

plt.ylabel("Frequency")

plt.legend()
print("{} tags are used more than 25 times".format(tag_df_sorted[tag_df_sorted["Counts"]>25].shape[0]))

print("{} tags are used more than 50 times".format(tag_df_sorted[tag_df_sorted["Counts"]>50].shape[0]))
tag_to_count_map

tupl = dict(tag_to_count_map.items())

word_cloud = WordCloud(width=1600,height=800,).generate_from_frequencies(tupl)

plt.figure(figsize = (12,8))

plt.imshow(word_cloud)

plt.axis('off')

plt.tight_layout(pad=0)
i=np.arange(20)

tag_df_sorted.head(20).plot(kind='bar')

plt.title('Frequency of top 20 tags')

plt.xticks(i, tag_df_sorted['Tags'])

plt.xlabel('Tags')

plt.ylabel('Counts')

plt.show()
stop_words = set(stopwords.words('english'))

stemmer = SnowballStemmer("english")
qus_list=[]

qus_with_code = 0

len_before_preprocessing = 0 

len_after_preprocessing = 0 

for index,row in df.iterrows():

    title, body, tags = row["Title"], row["Body"], row["Tags"]

    if '<code>' in body:

        qus_with_code+=1

    len_before_preprocessing+=len(title) + len(body)

    body=re.sub('<code>(.*?)</code>', '', body, flags=re.MULTILINE|re.DOTALL)

    body = re.sub('<.*?>', ' ', str(body.encode('utf-8')))

    title=title.encode('utf-8')

    question=str(title)+" "+str(body)

    question=re.sub(r'[^A-Za-z]+',' ',question)

    words=word_tokenize(str(question.lower()))

    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))

    qus_list.append(question)

    len_after_preprocessing += len(question)

df["question"] = qus_list

avg_len_before_preprocessing=(len_before_preprocessing*1.0)/df.shape[0]

avg_len_after_preprocessing=(len_after_preprocessing*1.0)/df.shape[0]

print( "Avg. length of questions(Title+Body) before preprocessing: ", avg_len_before_preprocessing)

print( "Avg. length of questions(Title+Body) after preprocessing: ", avg_len_after_preprocessing)

print ("% of questions containing code: ", (qus_with_code*100.0)/df.shape[0])
preprocessed_df = df[["question","Tags"]]

print("Shape of preprocessed data :", preprocessed_df.shape)
vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary='true')

y_multilabel = vectorizer.fit_transform(preprocessed_df['Tags'])
def tags_to_consider(n):

    tag_i_sum = y_multilabel.sum(axis=0).tolist()[0]

    sorted_tags_i = sorted(range(len(tag_i_sum)), key=lambda i: tag_i_sum[i], reverse=True)

    yn_multilabel=y_multilabel[:,sorted_tags_i[:n]]

    return yn_multilabel



def questions_covered_fn(numb):

    yn_multilabel = tags_to_consider(numb)

    x= yn_multilabel.sum(axis=1)

    return (np.count_nonzero(x==0))
questions_covered = []

total_tags=y_multilabel.shape[1]

total_qus=preprocessed_df.shape[0]

for i in range(100, total_tags, 100):

    questions_covered.append(np.round(((total_qus-questions_covered_fn(i))/total_qus)*100,3))
plt.plot(np.arange(100,total_tags, 100),questions_covered)

plt.xlabel("Number of tags")

plt.ylabel("Number of questions covered partially")

plt.grid()

plt.show()

print(questions_covered[9],"% of questions covered by 1000 tags")

print("Number of questions that are not covered by 100 tags : ", questions_covered_fn(1000),"out of ", total_qus)
yx_multilabel = tags_to_consider(1000)

print("Number of tags in the subset :", y_multilabel.shape[1])

print("Number of tags considered :", yx_multilabel.shape[1],"(",(yx_multilabel.shape[1]/y_multilabel.shape[1])*100,"%)")
X_train, X_test, y_train, y_test = train_test_split(preprocessed_df, yx_multilabel, test_size = 0.2,random_state = 42)

print("Number of data points in training data :", X_train.shape[0])

print("Number of data points in test data :", X_test.shape[0])
vectorizer = TfidfVectorizer(min_df=0.00009, max_features=200000, tokenizer = lambda x: x.split(), ngram_range=(1,3))

X_train_multilabel = vectorizer.fit_transform(X_train['question'])

X_test_multilabel = vectorizer.transform(X_test['question'])
print("Training data shape X : ",X_train_multilabel.shape, "Y :",y_train.shape)

print("Test data shape X : ",X_test_multilabel.shape,"Y:",y_test.shape)
clf = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l2'))

clf.fit(X_train_multilabel, y_train)

y_pred = clf.predict(X_test_multilabel)
print("Accuracy :",metrics.accuracy_score(y_test,y_pred))

print("Macro f1 score :",metrics.f1_score(y_test, y_pred, average = 'macro'))

print("Micro f1 scoore :",metrics.f1_score(y_test, y_pred, average = 'micro'))

print("Hamming loss :",metrics.hamming_loss(y_test,y_pred))

#print("Precision recall report :\n",metrics.classification_report(y_test, y_pred))
qus_list=[]

qus_with_code = 0

len_before_preprocessing = 0 

len_after_preprocessing = 0 

for index,row in df.iterrows():

    title, body, tags = row["Title"], row["Body"], row["Tags"]

    if '<code>' in body:

        qus_with_code+=1

    len_before_preprocessing+=len(title) + len(body)

    body=re.sub('<code>(.*?)</code>', '', body, flags=re.MULTILINE|re.DOTALL)

    body = re.sub('<.*?>', ' ', str(body.encode('utf-8')))

    title=title.encode('utf-8')

    question=str(title)+" "+str(title)+" "+str(title)+" "+ body

    question=re.sub(r'[^A-Za-z]+',' ',question)

    words=word_tokenize(str(question.lower()))

    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))

    qus_list.append(question)

    len_after_preprocessing += len(question)

df["question_with_more_wt_title"] = qus_list

avg_len_before_preprocessing=(len_before_preprocessing*1.0)/df.shape[0]

avg_len_after_preprocessing=(len_after_preprocessing*1.0)/df.shape[0]

print( "Avg. length of questions(Title+Body) before preprocessing: ", avg_len_before_preprocessing)

print( "Avg. length of questions(Title+Body) after preprocessing: ", avg_len_after_preprocessing)

print ("% of questions containing code: ", (qus_with_code*100.0)/df.shape[0])

preprocessed_df = df[["question_with_more_wt_title","Tags"]]

print("Shape of preprocessed data :", preprocessed_df.shape)
X_train, X_test, y_train, y_test = train_test_split(preprocessed_df, yx_multilabel, test_size = 0.2,random_state = 42)

print("Number of data points in training data :", X_train.shape[0])

print("Number of data points in test data :", X_test.shape[0])
vectorizer = TfidfVectorizer(min_df=0.00009, max_features=200000, tokenizer = lambda x: x.split(), ngram_range=(1,3))

X_train_multilabel = vectorizer.fit_transform(X_train['question_with_more_wt_title'])

X_test_multilabel = vectorizer.transform(X_test['question_with_more_wt_title'])
print("Training data shape X : ",X_train_multilabel.shape, "Y :",y_train.shape)

print("Test data shape X : ",X_test_multilabel.shape,"Y:",y_test.shape)
clf = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l2'))

clf.fit(X_train_multilabel, y_train)

y_pred = clf.predict(X_test_multilabel)
print("Accuracy :",metrics.accuracy_score(y_test,y_pred))

print("Macro f1 score :",metrics.f1_score(y_test, y_pred, average = 'macro'))

print("Micro f1 scoore :",metrics.f1_score(y_test, y_pred, average = 'micro'))

print("Hamming loss :",metrics.hamming_loss(y_test,y_pred))
#using direct implementation of Logistic Regression

clf2 = OneVsRestClassifier(LogisticRegression(penalty='l1'))

clf2.fit(X_train_multilabel, y_train)

y_pred2 = clf2.predict(X_test_multilabel)
print("Accuracy :",metrics.accuracy_score(y_test,y_pred2))

print("Macro f1 score :",metrics.f1_score(y_test, y_pred2, average = 'macro'))

print("Micro f1 scoore :",metrics.f1_score(y_test, y_pred2, average = 'micro'))

print("Hamming loss :",metrics.hamming_loss(y_test,y_pred2))
clf2.predict()